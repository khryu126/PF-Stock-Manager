import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime

# --- [1. ê¸°ë³¸ ì„¤ì • ë° ë§ˆìŠ¤í„° ë°ì´í„°] ---
st.set_page_config(page_title="PÂ·Forecast Stock Manager", layout="wide")

LT_MASTER = {
    'SH': 1, 'KD': 2, 'QZ': 2, 'SE': 6, 'SRL': 8, 'SP': 8
}

# --- [2. ë°ì´í„° ì •ì œ ë° ë¡œë“œ ìœ í‹¸ë¦¬í‹°] ---
def clean_numeric(series):
    if series.dtype == 'object':
        series = series.astype(str).str.replace(',', '').str.replace('"', '').str.strip()
        series = series.replace(['', 'nan', 'None'], np.nan)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def parse_date(series):
    return pd.to_datetime(series, errors='coerce')

def smart_load_csv(file):
    """ë¹ˆ ì¤„ ê±´ë„ˆë›°ê¸° ë° ë‹¤ì¤‘ ì¸ì½”ë”© ì§€ì› ì§€ëŠ¥í˜• ë¡œë”"""
    try:
        # í•œêµ­ì–´ ì—‘ì…€ CSV ì „ìš© ì¸ì½”ë”© ë¦¬ìŠ¤íŠ¸
        encodings = ['cp949', 'utf-8-sig', 'utf-8', 'euc-kr']
        for enc in encodings:
            try:
                file.seek(0)
                df = pd.read_csv(file, encoding=enc)
                # ë°ì´í„°ê°€ ë„ˆë¬´ ì ê±°ë‚˜ ì œëª©ì´ Unnamedë¡œë§Œ ë˜ì–´ ìˆìœ¼ë©´ í•œ ì¤„ ì•„ë˜ë¶€í„° ë‹¤ì‹œ ì‹œë„
                if df.columns.str.contains('Unnamed').sum() > len(df.columns) * 0.5:
                    for i in range(1, 4):
                        file.seek(0)
                        df = pd.read_csv(file, skiprows=i, encoding=enc)
                        if not df.columns.str.contains('Unnamed').all():
                            break
                return df
            except:
                continue
        return None
    except Exception as e:
        return None

def get_pattern_group(df_item, target_id):
    target_id = str(target_id).strip()
    related = {target_id}
    if df_item is not None:
        # 'ìƒí’ˆì½”ë“œ', 'ì´ì „ìƒí’ˆì½”ë“œ', 'ë³€ê²½ìƒí’ˆì½”ë“œ' ì»¬ëŸ¼ ì¤‘ ì¡´ì¬í•˜ëŠ” ê²ƒë§Œ í™œìš©
        search_cols = [c for c in ['ìƒí’ˆì½”ë“œ', 'ì´ì „ìƒí’ˆì½”ë“œ', 'ë³€ê²½ìƒí’ˆì½”ë“œ'] if c in df_item.columns]
        if search_cols:
            query = " | ".join([f"(`{c}` == '{target_id}')" for c in search_cols])
            try:
                links = df_item.query(query)
                for _, row in links.iterrows():
                    for col in search_cols:
                        val = str(row[col]).strip()
                        if val and val.lower() != 'nan' and val != '0':
                            related.add(val)
            except:
                pass
    return list(related)

# --- [3. ìƒì„¸ íŒì—…ì°½] ---
@st.dialog("í˜„ì¥ë³„ ìˆ˜ì£¼ ìƒì„¸ ë‚´ì—­")
def show_detail_dialog(group_ids, df_bl):
    st.write(f"ğŸ” ë¶„ì„ í’ˆë²ˆ ê·¸ë£¹: {', '.join(group_ids)}")
    detail = df_bl[df_bl['ìƒí’ˆì½”ë“œ'].isin(group_ids)].copy()
    if detail.empty:
        st.info("ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    today = datetime.now()
    detail['ìƒíƒœ'] = detail['ë‚©í’ˆì˜ˆì •ì¼'].apply(lambda x: "âš ï¸ ë‚©ê¸°ê²½ê³¼" if pd.notnull(x) and x < today else "ì •ìƒ")
    cols = ['ìƒíƒœ', 'í˜„ì¥ëª…', 'ê±´ì„¤ì‚¬', 'ìˆ˜ì£¼ì”ëŸ‰', 'ë‚©í’ˆì˜ˆì •ì¼', 'ë©”ëª¨']
    actual_cols = [c for c in cols if c in detail.columns]
    st.dataframe(detail[actual_cols].sort_values('ë‚©í’ˆì˜ˆì •ì¼'), use_container_width=True, hide_index=True)

# --- [4. ë©”ì¸ UI ë° íŒŒì¼ ì¸ì‹ ë¡œì§] ---
st.title("ğŸ“¦ PÂ·Forecast Stock Manager")
st.caption("íŠ¹íŒ ëª¨ì–‘ì§€ í†µí•© ìˆ˜ê¸‰ ì˜ˆì¸¡ ì‹œìŠ¤í…œ (ë¦¬ë“œíƒ€ì„ ë° í’ˆë²ˆ ì—°ê³„ ëŒ€ì‘)")

uploaded_files = st.sidebar.file_uploader("5ì¢…ì˜ CSV íŒŒì¼ì„ í•œêº¼ë²ˆì— ì„ íƒí•˜ì„¸ìš”", accept_multiple_files=True)

data = {}
# íŒŒì¼ íŒë³„ì„ ìœ„í•œ ë³µí•© í‚¤ì›Œë“œ ì‚¬ì „
RECOGNITION_MAP = {
    "backlog": {"name": "ìˆ˜ì£¼ì˜ˆì •(Demand)", "keys": ["ìˆ˜ì£¼ì”ëŸ‰", "í˜„ì¥ëª…", "ì´ì˜ˆìƒìˆ˜ëŸ‰"], "found": False},
    "po": {"name": "êµ¬ë§¤ë°œì£¼(PO)", "keys": ["POì”ëŸ‰", "ë¯¸ì„ ì ", "B/P weight"], "found": False},
    "stock": {"name": "í˜„ì¬ê³ (Stock)", "keys": ["ì¬ê³ ìˆ˜ëŸ‰", "í˜„ì¬ê³ ì•¡", "ë³¸ì‚¬ì°½ê³ "], "found": False},
    "item": {"name": "í’ˆëª©ì •ë³´(Master)", "keys": ["ìµœì¢…ìƒì‚°ì§€", "ì´ì „ìƒí’ˆì½”ë“œ", "ë³€ê²½ìƒí’ˆì½”ë“œ"], "found": False},
    "retail": {"name": "ì‹œíŒìŠ¤í™(Retail)", "keys": ["ì¶œì‹œì˜ˆì •", "4ê°œì›”íŒë§¤ëŸ‰", "ì œì‹œë‹¨ê°€", "ì‹œíŒ"], "found": False}
}

unrecognized_files = []

if uploaded_files:
    for f in uploaded_files:
        df = smart_load_csv(f)
        if df is not None:
            df.columns = [str(c).strip() for c in df.columns]
            cols_text = "|".join(df.columns)
            
            matched = False
            for file_id, info in RECOGNITION_MAP.items():
                if any(k in cols_text for k in info["keys"]):
                    data[file_id] = df
                    RECOGNITION_MAP[file_id]["found"] = True
                    matched = True
                    break
            if not matched:
                unrecognized_files.append({"filename": f.name, "columns": df.columns.tolist()})

# ì‚¬ì´ë“œë°” ë¡œë“œ ìƒíƒœ ë° ë””ë²„ê¹… ì •ë³´
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“ ë°ì´í„° ë¡œë“œ ìƒíƒœ")
for k, v in RECOGNITION_MAP.items():
    if v["found"]: st.sidebar.success(f"âœ… {v['name']}")
    else: st.sidebar.error(f"âŒ {v['name']} (ë¯¸ì¸ì‹)")

if unrecognized_files:
    with st.sidebar.expander("âš ï¸ ë¯¸ì¸ì‹ íŒŒì¼ ì»¬ëŸ¼ í™•ì¸"):
        for f in unrecognized_files:
            st.text(f"íŒŒì¼: {f['filename']}")
            st.caption(f"ê°ì§€ëœ ì»¬ëŸ¼: {', '.join(f['columns'][:5])}...")

# ë¶„ì„ ì‹œì‘
if len(data) >= 5:
    st.success("âœ… ëª¨ë“  íŒŒì¼ì´ ì¸ì‹ë˜ì—ˆìŠµë‹ˆë‹¤. ë¶„ì„ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    df_item, df_bl, df_po, df_st, df_retail = data['item'], data['backlog'], data['po'], data['stock'], data['retail']

    # ë°ì´í„° ì •ì œ
    for df_key in ['backlog', 'po', 'stock', 'retail']:
        df = data[df_key]
        for col in df.columns:
            if any(k in col for k in ['ì”ëŸ‰', 'ìˆ˜ëŸ‰', 'í˜„ì¬ê³ ', 'weight', 'í‰ëŸ‰', 'íŒë§¤ëŸ‰']):
                df[col] = clean_numeric(df[col])
    
    df_bl['ë‚©í’ˆì˜ˆì •ì¼'] = parse_date(df_bl['ë‚©í’ˆì˜ˆì •ì¼'])
    df_po['ì…ê³ ìš”ì²­ì¼'] = parse_date(df_po.get('ì…ê³ ìš”ì²­ì¼', df_po.get('POì¼ì')))

    # íƒ€ì„ë¼ì¸ ì„¤ì •
    today_base = datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0)
    months = [today_base + pd.DateOffset(months=i) for i in range(12)]
    month_cols = [m.strftime('%Y-%m') for m in months]

    # ë¶„ì„ ëŒ€ìƒ (ìˆ˜ì£¼ì”ëŸ‰ ìˆëŠ” í’ˆë²ˆ)
    target_ids = df_bl[df_bl['ìˆ˜ì£¼ì”ëŸ‰'] > 0]['ìƒí’ˆì½”ë“œ'].unique()
    matrix_rows = []
    processed_groups = set()

    for pid in target_ids:
        group = sorted(get_pattern_group(df_item, pid))
        group_key = tuple(group)
        if group_key in processed_groups: continue
        processed_groups.add(group_key)

        # ê¸°ì´ˆ ì •ë³´
        item_rows = df_item[df_item['ìƒí’ˆì½”ë“œ'].isin(group)]
        item_info = item_rows.iloc[0] if not item_rows.empty else {}
        site_code = str(item_info.get('ìµœì¢…ìƒì‚°ì§€ëª…', item_info.get('ìµœì¢…ìƒì‚°ì§€', 'ETC')))
        lt = LT_MASTER.get(site_code, 0)
        
        # ì‹œíŒ/ì—°ê³„ íƒœê·¸ (ì»¬ëŸ¼ ìœ„ì¹˜ ê¸°ë°˜ ìœ ì—°í™”)
        is_retail = "ğŸ·ï¸" if any(str(g) in df_retail.iloc[:, 8].astype(str).values for g in group) else ""
        has_chain = "ğŸ”„" if len(group) > 1 else ""
        
        # ìˆ˜ì§€ ê³„ì‚°
        # í˜„ì¬ê³  (í˜„ì¬ê³  ì»¬ëŸ¼ ë˜ëŠ” ìˆ˜ëŸ‰ ì»¬ëŸ¼ í•©ì‚°)
        st_cols = [c for c in df_st.columns if 'ì¬ê³ ìˆ˜ëŸ‰' in c or 'í˜„ì¬ê³ ' in c]
        total_stk = df_st[df_st.get('í’ˆë²ˆ', df_st.columns[0]).isin(group)][st_cols[0]].sum() if st_cols else 0
        
        overdue_dem = df_bl[(df_bl['ìƒí’ˆì½”ë“œ'].isin(group)) & (df_bl['ë‚©í’ˆì˜ˆì •ì¼'] < today_base)]['ìˆ˜ì£¼ì”ëŸ‰'].sum()
        
        running_inv = total_stk - overdue_dem
        row_dem = {"ë‚©ê¸°ê²½ê³¼": overdue_dem}
        row_stk = {"ë‚©ê¸°ê²½ê³¼": running_inv}

        for m_date in months:
            m_str = m_date.strftime('%Y-%m')
            # ì†Œìš”ëŸ‰
            m_d = df_bl[(df_bl['ìƒí’ˆì½”ë“œ'].isin(group)) & (df_bl['ë‚©í’ˆì˜ˆì •ì¼'] >= m_date) & (df_bl['ë‚©í’ˆì˜ˆì •ì¼'] < m_date + pd.DateOffset(months=1))]['ìˆ˜ì£¼ì”ëŸ‰'].sum()
            # ì…ê³ ëŸ‰
            m_p = df_po[(df_po.get('í’ˆë²ˆ', df_po.columns[0]).isin(group)) & (df_po['ì…ê³ ìš”ì²­ì¼'] >= m_date) & (df_po['ì…ê³ ìš”ì²­ì¼'] < m_date + pd.DateOffset(months=1))]
            m_s = 0
            for _, r in m_p.iterrows():
                bw = clean_numeric(pd.Series([r.get('B/P weight', 70)]))[0]
                m_s += (clean_numeric(pd.Series([r.get('POì”ëŸ‰(ë¯¸ì„ ì )', 0)]))[0] * 1000) / ((bw if bw > 0 else 70) * 1.26)
            
            running_inv = (running_inv + m_s) - m_d
            row_dem[m_str] = round(m_d, 0)
            row_stk[m_str] = round(running_inv, 0)

        title = f"{pid} {is_retail}{has_chain}{'âš ï¸' if overdue_dem > 0 else ''}"
        common = {"í’ˆë²ˆ": title, "ìƒì‚°ì§€(LT)": f"{site_code}({lt}M)", "group": group}
        matrix_rows.append({**common, "êµ¬ë¶„": "ì†Œìš”ëŸ‰(m)", **row_dem})
        matrix_rows.append({**common, "êµ¬ë¶„": "ì˜ˆìƒì¬ê³ (m)", **row_stk})

    if matrix_rows:
        res_df = pd.DataFrame(matrix_rows)
        
        def style_matrix(row):
            styles = [''] * len(row)
            if row['êµ¬ë¶„'] == "ì˜ˆìƒì¬ê³ (m)":
                try:
                    lt_val = int(row['ìƒì‚°ì§€(LT)'].split('(')[1].replace('M)', ''))
                except: lt_val = 0
                for i, col in enumerate(row.index):
                    if col == "ë‚©ê¸°ê²½ê³¼" and row[col] < 0:
                        styles[i] = 'background-color: #9e0000; color: white'
                    elif '-' in col and row[col] < 0:
                        col_dt = datetime.strptime(col, '%Y-%m')
                        limit_dt = today_base + pd.DateOffset(months=lt_val)
                        styles[i] = 'background-color: #ff4b4b; color: white' if col_dt <= limit_dt else 'background-color: #ffeb3b; color: black'
            return styles

        selection = st.dataframe(
            res_df.style.apply(style_matrix, axis=1),
            use_container_width=True, hide_index=True,
            column_order=["í’ˆë²ˆ", "ìƒì‚°ì§€(LT)", "êµ¬ë¶„", "ë‚©ê¸°ê²½ê³¼"] + month_cols,
            on_select="rerun", selection_mode="single_row"
        )

        if selection.selection.rows:
            sel_idx = selection.selection.rows[0]
            if st.button(f"ğŸ” {res_df.iloc[sel_idx]['í’ˆë²ˆ']} ìƒì„¸ ì •ë³´ íŒì—…"):
                show_detail_dialog(res_df.iloc[sel_idx]['group'], df_bl)
else:
    st.info("ì‚¬ì´ë“œë°”ì— 5ì¢…ì˜ íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”. ë¯¸ì¸ì‹ ì‹œ ì‚¬ì´ë“œë°”ì˜ 'ì»¬ëŸ¼ í™•ì¸'ì„ ì°¸ì¡°í•˜ì„¸ìš”.")
