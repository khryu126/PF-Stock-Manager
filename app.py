import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

# --- [1. ì„¤ì • ë° ë¦¬ë“œíƒ€ìž„ ë§ˆìŠ¤í„°] ---
st.set_page_config(page_title="PÂ·Forecast Stock Manager", layout="wide")

# ë¦¬ë“œíƒ€ìž„ ì„¤ì • (ì´ LT / ìš´ì†¡ LT)
LT_CONFIG = {
    'SE': {'total': 6, 'ship_days': 90},   # ë…ì¼: ì´ 6ê°œì›” / ì„ ì  3ê°œì›”
    'SRL': {'total': 8, 'ship_days': 90},  # ì´íƒœë¦¬: ì´ 8ê°œì›” / ì„ ì  3ê°œì›”
    'SP': {'total': 8, 'ship_days': 90},   # í´ëž€ë“œ
    'SH': {'total': 1, 'ship_days': 30},   # ìƒí•´: ì´ 1ê°œì›” / ì„ ì  1ê°œì›”
    'KD': {'total': 2, 'ship_days': 30},   # ì¤‘êµ­
    'QZ': {'total': 2, 'ship_days': 30}    # ê´‘ì €ìš°
}

# --- [2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---
def clean_numeric(series):
    if series.dtype == 'object':
        series = series.astype(str).str.replace(',', '').str.replace('"', '').str.strip()
        series = series.replace(['', 'nan', 'None'], np.nan)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def parse_date_smart(series):
    s = series.astype(str).str.replace('.0', '', regex=False).str.strip()
    return pd.to_datetime(s, format='%Y%m%d', errors='coerce')

def smart_load_csv(file):
    for enc in ['cp949', 'utf-8-sig', 'utf-8']:
        try:
            file.seek(0)
            df = pd.read_csv(file, encoding=enc)
            if df.columns.str.contains('Unnamed').sum() > len(df.columns) * 0.4:
                for i in range(1, 6):
                    file.seek(0)
                    df = pd.read_csv(file, skiprows=i, encoding=enc)
                    if not df.columns.str.contains('Unnamed').all(): break
            return df
        except: continue
    return None

# --- [3. ìƒì„¸ íŒì—…ì°½] ---
@st.dialog("í˜„ìž¥ë³„ ìƒì„¸ ìˆ˜ì£¼ ë‚´ì—­", width="large")
def show_detail_popup(group_ids, df_bl, cutoff_date):
    st.write(f"ðŸ”Ž ë¶„ì„ ëŒ€ìƒ í’ˆë²ˆ ê·¸ë£¹: {', '.join(group_ids)}")
    code_col = 'ìƒí’ˆì½”ë“œ' if 'ìƒí’ˆì½”ë“œ' in df_bl.columns else df_bl.columns[5]
    detail = df_bl[df_bl[code_col].astype(str).isin(group_ids)].copy()
    detail = detail[(detail['clean_qty'] > 0) & (detail['dt_clean'] >= cutoff_date)]
    if detail.empty:
        st.info("ì¡°ê±´ì— ë§žëŠ” ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    st.dataframe(detail.sort_values('dt_clean', ascending=True), use_container_width=True, hide_index=True)

# --- [4. ë©”ì¸ UI ë° íŒŒì¼ ìƒíƒœì°½] ---
st.title("ðŸš€ PÂ·Forecast Stock Manager v5.2")

RECOGNITION = {
    "backlog": {"name": "ìˆ˜ì£¼ì˜ˆì •(Demand)", "keys": ["ìˆ˜ì£¼ìž”ëŸ‰", "ì´ì˜ˆìƒìˆ˜ëŸ‰"], "found": False},
    "po": {"name": "êµ¬ë§¤ë°œì£¼(PO)", "keys": ["POìž”ëŸ‰", "ë¯¸ì„ ì "], "found": False},
    "stock": {"name": "í˜„ìž¬ê³ (Stock)", "keys": ["ìž¬ê³ ìˆ˜ëŸ‰", "í˜„ìž¬ê³ ì•¡"], "found": False},
    "item": {"name": "í’ˆëª©ì •ë³´(Master)", "keys": ["ìµœì¢…ìƒì‚°ì§€ëª…", "ì´ì „ìƒí’ˆì½”ë“œ"], "found": False},
    "retail": {"name": "ì‹œíŒìŠ¤íŽ™(Retail)", "keys": ["ì¶œì‹œì˜ˆì •", "4ê°œì›”íŒë§¤ëŸ‰"], "found": False}
}

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    start_date_val = st.date_input("ê²€í†  ì‹œì (ì¡°íšŒ ì‹œìž‘ì¼)", datetime.now())
    freq_opt = st.selectbox("ì§‘ê³„ ë‹¨ìœ„", ["ì£¼ë³„", "ì›”ë³„", "ë¶„ê¸°ë³„", "ë…„ë„ë³„"], index=1)
    exclude_months = st.slider("ê³¼ê±° ìˆ˜ì£¼ ì œì™¸ (Nê°œì›” ê²½ê³¼)", 1, 36, 12)
    cutoff_date = pd.Timestamp(start_date_val) - relativedelta(months=exclude_months)
    
    st.markdown("---")
    search_query = st.text_input("ðŸ” í’ˆëª…/í’ˆë²ˆ í‚¤ì›Œë“œ ê²€ìƒ‰", "")
    
    st.markdown("---")
    st.subheader("ðŸ“ íŒŒì¼ ë¡œë“œ ìƒíƒœ")
    uploaded_files = st.file_uploader("5ì¢… CSV íŒŒì¼ ì—…ë¡œë“œ", accept_multiple_files=True)

data = {}
if uploaded_files:
    for f in uploaded_files:
        df = smart_load_csv(f)
        if df is not None:
            df.columns = [str(c).strip() for c in df.columns]
            cols = "|".join(df.columns)
            for k, v in RECOGNITION.items():
                if any(key in cols for key in v["keys"]):
                    data[k] = df
                    RECOGNITION[k]["found"] = True
                    break

with st.sidebar:
    for k, v in RECOGNITION.items():
        if v["found"]: st.success(f"âœ… {v['name']} (ì™„ë£Œ)")
        else: st.warning(f"â³ {v['name']} (ëŒ€ê¸°ì¤‘)")

# --- [5. ë©”ì¸ ë¶„ì„ ë¡œì§] ---
if len(data) >= 5:
    with st.spinner('ì •ë°€ ìˆ˜ê¸‰ ë¶„ì„ ì¤‘...'):
        df_item, df_bl, df_po, df_st, df_retail = data['item'], data['backlog'], data['po'], data['stock'], data['retail']
        
        today_dt = pd.Timestamp(datetime.now().date())
        base_dt = pd.Timestamp(start_date_val)

        # 1. ìˆ˜ì£¼/ìž¬ê³  ì •ì œ
        bl_code = 'ìƒí’ˆì½”ë“œ' if 'ìƒí’ˆì½”ë“œ' in df_bl.columns else df_bl.columns[5]
        df_bl['clean_qty'] = clean_numeric(df_bl['ìˆ˜ì£¼ìž”ëŸ‰'])
        df_bl['dt_clean'] = parse_date_smart(df_bl['ë‚©í’ˆì˜ˆì •ì¼' if 'ë‚©í’ˆì˜ˆì •ì¼' in df_bl.columns else df_bl.columns[24]])
        df_bl = df_bl[df_bl['dt_clean'] >= cutoff_date].copy()

        st_code = 'í’ˆë²ˆ' if 'í’ˆë²ˆ' in df_st.columns else df_st.columns[7]
        df_st['clean_qty'] = clean_numeric(df_st['ìž¬ê³ ìˆ˜ëŸ‰' if 'ìž¬ê³ ìˆ˜ëŸ‰' in df_st.columns else df_st.columns[17]])

        # 2. PO ë°ì´í„° ì •ì œ (KG -> M ìžë™ í™˜ì‚° ë° ì§€ëŠ¥í˜• ë‚ ì§œ ë¡œì§)
        po_code = 'í’ˆë²ˆ' if 'í’ˆë²ˆ' in df_po.columns else df_po.columns[12]
        df_po['m_qty'] = clean_numeric(df_po['POìž”ëŸ‰(ë¯¸ì„ ì )']) * 11.3378 

        def calc_arrival_v52(row):
            site_raw = str(row.get('ìƒì‚°ì§€ëª…', ''))[:2].upper()
            lt_config = LT_CONFIG.get(site_raw, {'total': 0, 'ship_days': 0})
            
            # [ìˆ˜ì •ëœ ë‚ ì§œ ë¡œì§]
            prod_dt = parse_date_smart(pd.Series([row.get('ìƒì‚°ì˜ˆì •ì¼', np.nan)]))[0]
            
            if pd.notnull(prod_dt):
                # 1. ìƒì‚°ì˜ˆì •ì¼ì´ ìžˆìœ¼ë©´ ìš´ì†¡ ë¦¬ë“œíƒ€ìž„ë§Œ ë”í•¨
                return prod_dt + timedelta(days=int(lt_config['ship_days']))
            else:
                # 2. ìƒì‚°ì˜ˆì •ì¼ì´ ì—†ìœ¼ë©´ POì¼ìž(ë˜ëŠ” ì˜¤ëŠ˜)ë¡œë¶€í„° ì´ ë¦¬ë“œíƒ€ìž„ì„ ë”í•¨
                po_dt = parse_date_smart(pd.Series([row.get('POì¼ìž', row.get('ìž…ê³ ìš”ì²­ì¼', np.nan))]))[0]
                if pd.isna(po_dt): po_dt = today_dt # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ ê¸°ì¤€
                return po_dt + relativedelta(months=int(lt_config['total']))

        df_po['dt_arrival'] = df_po.apply(calc_arrival_v52, axis=1)

        # 3. ê¸°ê°„ ì¶• ë° ë£¨í”„
        freq_map = {"ì£¼ë³„": "W", "ì›”ë³„": "MS", "ë¶„ê¸°ë³„": "QS", "ë…„ë„ë³„": "YS"}
        date_range = pd.date_range(start=base_dt, periods=13, freq=freq_map[freq_opt])
        time_labels = [d.strftime('%Y-%m-%d' if freq_opt=="ì£¼ë³„" else '%Y-%m') for d in date_range[:12]]

        target_ids = df_bl[df_bl['clean_qty'] > 0][bl_code].unique()
        matrix_rows, alert_list = [], []
        idx_no = 1

        for pid in target_ids:
            pid_s = str(pid).strip()
            item_match = df_item[df_item['ìƒí’ˆì½”ë“œ'].astype(str).str.strip() == pid_s]
            p_name = str(item_match['ìƒí’ˆëª…'].iloc[0]) if not item_match.empty else "-"
            if search_query and (search_query.lower() not in p_name.lower() and search_query.lower() not in pid_s.lower()): continue

            prev = str(item_match['ì´ì „ìƒí’ˆì½”ë“œ'].iloc[0]) if not item_match.empty else ""
            chng = str(item_match['ë³€ê²½ìƒí’ˆì½”ë“œ'].iloc[0]) if not item_match.empty else ""
            prev = "" if prev in ["nan", "0", "-"] else prev
            chng = "" if chng in ["nan", "0", "-"] else chng

            group = list(set([pid_s, prev, chng])); group = [g for g in group if g]
            site_raw = str(item_match['ìµœì¢…ìƒì‚°ì§€ëª…'].iloc[0]) if not item_match.empty else "ETC"
            lt_total = LT_CONFIG.get(site_raw[:2].upper(), {'total': 0})['total']
            is_retail = " ðŸ·ï¸" if any(str(g) in df_retail.iloc[:, 8].astype(str).values for g in group) else ""

            # ìž¬ê³  ë° ì‚¬ê°ì§€ëŒ€ PO ì„ ë°˜ì˜
            main_stk = df_st[df_st[st_code].astype(str).str.strip().isin(group)]['clean_qty'].sum()
            gap_po_val = df_po[(df_po[po_code].astype(str).str.strip().isin(group)) & 
                               (df_po['dt_arrival'] >= today_dt) & 
                               (df_po['dt_arrival'] < base_dt)]['m_qty'].sum()
            
            total_start_stk = main_stk + gap_po_val
            po_total_m = df_po[df_po[po_code].astype(str).str.strip().isin(group)]['m_qty'].sum()

            overdue_dem = df_bl[(df_bl[bl_code].astype(str).str.strip().isin(group)) & (df_bl['dt_clean'] < base_dt)]['clean_qty'].sum()
            running_inv = total_start_stk - overdue_dem
            
            d_vals, p_vals, s_vals = {"ë‚©ê¸°ê²½ê³¼": overdue_dem}, {"ë‚©ê¸°ê²½ê³¼": gap_po_val}, {"ë‚©ê¸°ê²½ê³¼": running_inv}

            for i in range(12):
                start, end = date_range[i], date_range[i+1]
                m_dem = df_bl[(df_bl[bl_code].astype(str).str.strip().isin(group)) & (df_bl['dt_clean'] >= start) & (df_bl['dt_clean'] < end)]['clean_qty'].sum()
                m_sup = df_po[(df_po[po_code].astype(str).str.strip().isin(group)) & (df_po['dt_arrival'] >= start) & (df_po['dt_arrival'] < end)]['m_qty'].sum()
                
                running_inv = (running_inv + m_sup) - m_dem
                d_vals[time_labels[i]], p_vals[time_labels[i]], s_vals[time_labels[i]] = round(m_dem, 0), round(m_sup, 0), round(running_inv, 0)
                
                if running_inv < 0 and start < base_dt + relativedelta(months=lt_total):
                    alert_list.append({"í’ˆëª…": p_name, "í’ˆë²ˆ": pid_s, "ë¶€ì¡±ì‹œì ": time_labels[i], "ë¶€ì¡±ìˆ˜ëŸ‰": round(abs(running_inv), 0)})

            common = {"No": idx_no, "í’ˆëª…": p_name, "ìˆ˜ì£¼í’ˆë²ˆ": pid_s + is_retail, "ë³¸ì‚¬ìž¬ê³ ": total_start_stk, "POìž”ëŸ‰(m)": po_total_m, "ìƒì‚°ì§€": f"{site_raw[:2]}({lt_total}M)", "group": group}
            matrix_rows.append({**common, "êµ¬ë¶„": "ì†Œìš”ëŸ‰", "ì—°ê³„ì •ë³´": f"ì´ì „:{prev}" if prev else "", **d_vals})
            matrix_rows.append({"No": "", "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ìž¬ê³ ": np.nan, "POìž”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "group": group, "êµ¬ë¶„": "ìž…ê³ ëŸ‰(PO)", "ì—°ê³„ì •ë³´": "", **p_vals})
            matrix_rows.append({"No": idx_no, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ìž¬ê³ ": "", "POìž”ëŸ‰(m)": "", "ìƒì‚°ì§€": "", "group": group, "êµ¬ë¶„": "ì˜ˆìƒìž¬ê³ ", "ì—°ê³„ì •ë³´": f"ë³€ê²½:{chng}" if chng else "", **s_vals})
            idx_no += 1

    # [ê¸´ê¸‰ ì•ŒëžŒ ë²„íŠ¼]
    if alert_list:
        if st.button(f"âš ï¸ ê¸´ê¸‰ ë°œì£¼ ê²€í†  ëŒ€ìƒ ({len(pd.DataFrame(alert_list)['í’ˆë²ˆ'].unique())}ê±´)"):
            st.error("ë¦¬ë“œíƒ€ìž„ ë‚´ ìž¬ê³  ë¶€ì¡± ì˜ˆìƒ í’ˆëª©")
            st.table(pd.DataFrame(alert_list).drop_duplicates(subset=['í’ˆë²ˆ'], keep='first').style.format({"ë¶€ì¡±ìˆ˜ëŸ‰": "{:,.0f}"}))

    if matrix_rows:
        res_df = pd.DataFrame(matrix_rows)
        def style_fn(row):
            g_idx = (matrix_rows.index(row.to_dict()) // 3) if row.to_dict() in matrix_rows else 0
            bg = '#f9f9f9' if g_idx % 2 == 0 else '#ffffff'
            styles = [f'background-color: {bg}'] * len(row)
            for i, col in enumerate(row.index):
                if col == "êµ¬ë¶„": styles[i] = 'background-color: #e1f5fe; font-weight: bold'
                elif row['êµ¬ë¶„'] == "ì˜ˆìƒìž¬ê³ " and (col == "ë‚©ê¸°ê²½ê³¼" or col in time_labels):
                    if isinstance(row[col], (int, float)) and row[col] < 0: styles[i] = 'background-color: #ff4b4b; color: white'
            return styles

        st.subheader(f"ðŸ“Š ìˆ˜ê¸‰ ë¶„ì„ ë§¤íŠ¸ë¦­ìŠ¤ ({freq_opt} í•©ì‚°)")
        fmt_dict = {col: "{:,.0f}" for col in ["ë³¸ì‚¬ìž¬ê³ ", "POìž”ëŸ‰(m)", "ë‚©ê¸°ê²½ê³¼"] + time_labels}
        st_df = st.dataframe(
            res_df.style.apply(style_fn, axis=1).format(fmt_dict, na_rep=""),
            use_container_width=True, hide_index=True,
            column_order=["No", "í’ˆëª…", "ìˆ˜ì£¼í’ˆë²ˆ", "ë³¸ì‚¬ìž¬ê³ ", "POìž”ëŸ‰(m)", "ìƒì‚°ì§€", "ì—°ê³„ì •ë³´", "êµ¬ë¶„", "ë‚©ê¸°ê²½ê³¼"] + time_labels,
            on_select="rerun", selection_mode="single-row"
        )
        if st_df.selection.rows:
            s_idx = st_df.selection.rows[0]
            target = res_df.iloc[s_idx - (s_idx % 3)]
            if st.button(f"ðŸ” {target['ìˆ˜ì£¼í’ˆë²ˆ'].replace('ðŸ·ï¸','').strip()} ìƒì„¸ ë³´ê¸°"):
                show_detail_popup(target['group'], df_bl, cutoff_date)
else:
    st.info("ì‚¬ì´ë“œë°”ì— 5ì¢… íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
