import streamlit as st
import pandas as pd
import pickle
import numpy as np
import re
import os
import ssl
import torch
import torchvision.transforms as T
import cv2
import base64
from PIL import Image, ImageEnhance, ImageDraw
from io import BytesIO
from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input
from tensorflow.keras.preprocessing import image as k_image
from sklearn.metrics.pairwise import cosine_similarity
from streamlit_image_coordinates import streamlit_image_coordinates

# [0] í™˜ê²½ ì„¤ì •: SSL ìš°íšŒ (DINOv2 ë‹¤ìš´ë¡œë“œ ì—ëŸ¬ ë°©ì§€)
ssl._create_default_https_context = ssl._create_unverified_context

# --- [1] ìœ í‹¸ë¦¬í‹° ë° ë¦¬ì†ŒìŠ¤ ë¡œë“œ ---
def load_csv_smart(target_name):
    files = os.listdir('.')
    for f in files:
        if f.lower() == target_name.lower():
            for enc in ['utf-8-sig', 'cp949', 'utf-8', 'euc-kr']:
                try: return pd.read_csv(f, encoding=enc)
                except: continue
    st.error(f"âŒ {target_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

def get_digits(text):
    return "".join(re.findall(r'\d+', str(text))) if text else ""

@st.cache_resource
def init_resources():
    # ëª¨ë¸ 1: ResNet50 (ê²°/í…ìŠ¤ì²˜ ë¶„ì„)
    model_res = ResNet50(weights='imagenet', include_top=False, pooling='avg')
    # ëª¨ë¸ 2: DINOv2 (êµ¬ì¡°/íŒ¨í„´ ë¶„ì„)
    model_dino = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')
    model_dino.eval()
    
    # ë°ì´í„° ë¡œë“œ
    with open('material_features.pkl', 'rb') as f:
        feature_db = pickle.load(f)
        
    df_path = load_csv_smart('ì´ë¯¸ì§€ê²½ë¡œ.csv')
    df_info = load_csv_smart('í’ˆëª©ì •ë³´.csv')
    df_stock = load_csv_smart('í˜„ì¬ê³ .csv')
    
    # ì¬ê³  ë¡œì§ (ìœ  ëŒ€ë¦¬ë‹˜ ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    df_stock['ì¬ê³ ìˆ˜ëŸ‰'] = pd.to_numeric(df_stock['ì¬ê³ ìˆ˜ëŸ‰'].astype(str).str.replace(',', ''), errors='coerce').fillna(0)
    df_stock['í’ˆë²ˆ_KEY'] = df_stock['í’ˆë²ˆ'].astype(str).str.strip().str.upper()
    agg_stock = df_stock.groupby('í’ˆë²ˆ_KEY')['ì¬ê³ ìˆ˜ëŸ‰'].sum().to_dict()
    stock_date = str(int(df_stock['ì •ì‚°ì¼ì'].max())) if 'ì •ì‚°ì¼ì' in df_stock.columns else "í™•ì¸ë¶ˆê°€"
    
    return model_res, model_dino, feature_db, df_path, df_info, agg_stock, stock_date

res_model, dino_model, feature_db, df_path, df_info, agg_stock, stock_date = init_resources()

# [DINOv2 ì „ìš© ë³€í™˜]
dino_transform = T.Compose([
    T.Resize(224), T.CenterCrop(224), T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

@st.cache_data
def get_master_map():
    mapping = {}
    for _, row in df_info.iterrows():
        f = str(row.get('ìƒí’ˆì½”ë“œ', '')).strip()
        n = str(row.get('ìƒí’ˆëª…', '')).strip()
        d = get_digits(f)
        if d: mapping[d] = {'formal': f, 'name': n}
    return mapping

master_map = get_master_map()

# --- [2] ì´ë¯¸ì§€ ì²˜ë¦¬ ì—”ì§„ (Perspective & Filters) ---
def order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1); rect[0] = pts[np.argmin(s)]; rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1); rect[1] = pts[np.argmin(diff)]; rect[3] = pts[np.argmax(diff)]
    return rect

def four_point_transform(image, pts):
    rect = order_points(pts)
    (tl, tr, br, bl) = rect
    w1 = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    w2 = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    h1 = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    h2 = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    mW, mH = max(int(w1), int(w2)), max(int(h1), int(h2))
    dst = np.array([[0, 0], [mW - 1, 0], [mW - 1, mH - 1], [0, mH - 1]], dtype="float32")
    M = cv2.getPerspectiveTransform(rect, dst)
    return cv2.warpPerspective(image, M, (mW, mH))

def apply_smart_filters(img, category, lighting, brightness, sharpness):
    if lighting == 'ë°±ì—´ë“± (ëˆ„ëŸ° ì¡°ëª…)':
        r, g, b = img.split(); b = b.point(lambda i: i * 1.2); img = Image.merge('RGB', (r, g, b))
    en_con = ImageEnhance.Contrast(img); en_shp = ImageEnhance.Sharpness(img); en_bri = ImageEnhance.Brightness(img)
    if category != 'ì¼ë°˜':
        img = en_shp.enhance(2.0); img = en_con.enhance(1.1)
    if brightness != 1.0: img = en_bri.enhance(brightness)
    if sharpness != 1.0: img = en_shp.enhance(sharpness)
    return img

# --- [3] ë©”ì¸ UI ë ˆì´ì•„ì›ƒ ---
st.set_page_config(layout="wide", page_title="í•˜ì´ë¸Œë¦¬ë“œ ìì¬ ê²€ìƒ‰ v3.3")
st.title("ğŸŒ² í•˜ì´ë¸Œë¦¬ë“œ ìì¬ íŒ¨í„´ ê²€ìƒ‰ ì—”ì§„")
st.sidebar.info(f"ğŸ“… ì¬ê³  ê¸°ì¤€ì¼: {stock_date}")

if 'points' not in st.session_state: st.session_state['points'] = []
if 'search_done' not in st.session_state: st.session_state['search_done'] = False

uploaded = st.file_uploader("ğŸ“¸ ë¶„ì„í•  ìì¬ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['jpg','png','jpeg'])

if uploaded:
    if 'current_img_name' not in st.session_state or st.session_state['current_img_name'] != uploaded.name:
        st.session_state['points'] = []; st.session_state['search_done'] = False
        st.session_state['current_img_name'] = uploaded.name
        st.session_state['proc_img'] = Image.open(uploaded).convert('RGB')
        st.rerun()

    working_img = st.session_state['proc_img']
    w, h = working_img.size
    
    # ë³´ê¸° í¬ê¸° ì¡°ì ˆ
    scale = st.radio("ğŸ” ë³´ê¸° í¬ê¸°:", [0.3, 0.5, 0.7, 1.0], format_func=lambda x: f"{int(x*100)}%", index=1, horizontal=True)
    
    col_opt, col_pad = st.columns([1, 2])
    with col_opt:
        mat_type = st.selectbox("ğŸ§± ìì¬ ì¢…ë¥˜", ['ì¼ë°˜', 'ë§ˆë£¨/ìš°ë“œ (Wood)', 'í•˜ì´ê·¸ë¡œì‹œ/ìœ ê´‘ (Glossy)', 'ë²½ì§€/íŒ¨ë¸Œë¦­ (Texture)'])
        s_mode = st.radio("ğŸ” ê²€ìƒ‰ ëª¨ë“œ", ["ì¢…í•© ê²€ìƒ‰(6:4)", "íŒ¨í„´ ì¤‘ì‹¬(í‘ë°±)"], horizontal=True)
        bri = st.slider("ë°ê¸°", 0.5, 2.0, 1.0, 0.1)
        shp = st.slider("ì„ ëª…ë„", 0.0, 3.0, 1.5, 0.1)
        if st.button("âŒ ì„ íƒ ì´ˆê¸°í™”"): st.session_state['points'] = []; st.rerun()

    with col_pad:
        d_img = working_img.resize((int(w*scale), int(h*scale)), Image.Resampling.LANCZOS)
        draw = ImageDraw.Draw(d_img)
        for i, p in enumerate(st.session_state['points']):
            px, py = p[0]*scale, p[1]*scale
            draw.ellipse((px-8, py-8, px+8, py+8), fill='red', outline='white')
        
        value = streamlit_image_coordinates(d_img, key="coords")
        if value and len(st.session_state['points']) < 4:
            new_p = (value['x']/scale, value['y']/scale)
            if not st.session_state['points'] or st.session_state['points'][-1] != new_p:
                st.session_state['points'].append(new_p); st.rerun()

    if len(st.session_state['points']) == 4:
        warped = four_point_transform(np.array(working_img), np.array(st.session_state['points'], dtype="float32"))
        final_img = Image.fromarray(warped)
        final_img = apply_smart_filters(final_img, mat_type, 'ì¼ë°˜', bri, shp)
        if s_mode == "íŒ¨í„´ ì¤‘ì‹¬(í‘ë°±)": final_img = final_img.convert("L").convert("RGB")
        
        st.image(final_img, width=300, caption="ë¶„ì„ ì˜ì—­")
        
        if st.button("ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘", type="primary", use_container_width=True):
            with st.spinner('ê²°(ResNet)ê³¼ êµ¬ì¡°(DINO)ë¥¼ 6:4 ë¹„ìœ¨ë¡œ ë¶„ì„ ì¤‘...'):
                # 1. ì‚¬ìš©ì ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ (Hybrid)
                x_res = k_image.img_to_array(final_img.resize((224, 224)))
                q_res = res_model.predict(preprocess_input(np.expand_dims(x_res, axis=0)), verbose=0).flatten()
                
                d_in = dino_transform(final_img).unsqueeze(0)
                with torch.no_grad():
                    q_dino = dino_model(d_in).cpu().numpy().flatten()

                # 2. ìœ ì‚¬ë„ ê³„ì‚° (0.6:0.4 ê°€ì¤‘ì¹˜ í•©ì‚°)
                all_results = []
                for fn, db_vec in feature_db.items():
                    db_res = db_vec[:2048]
                    db_dino = db_vec[2048:]
                    
                    s_res = cosine_similarity([q_res], [db_res])[0][0]
                    s_dino = cosine_similarity([q_dino], [db_dino])[0][0]
                    total_sim = (s_res * 0.6) + (s_dino * 0.4)
                    
                    # ì •ë³´ ë§¤ì¹­
                    info = master_map.get(get_digits(fn), {'formal': fn, 'name': 'ì •ë³´ ì—†ìŒ'})
                    qty = agg_stock.get(info['formal'].strip().upper(), 0)
                    url_row = df_path[df_path['ì¶”ì¶œëœ_í’ˆë²ˆ'].apply(get_digits) == get_digits(fn)]
                    url = url_row['ì¹´ì¹´ì˜¤í†¡_ì „ì†¡ìš©_URL'].values[0] if not url_row.empty else None
                    
                    if url:
                        all_results.append({'formal': info['formal'], 'name': info['name'], 'score': total_sim, 'stock': qty, 'url': url})

                all_results.sort(key=lambda x: x['score'], reverse=True)
                st.session_state['search_results'] = all_results[:20]
                st.session_state['search_done'] = True; st.rerun()

# --- [4] ê²°ê³¼ ì¶œë ¥ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì´ë¯¸ì§€ ì§ì ‘ ì—°ê²°) ---
if st.session_state.get('search_done'):
    st.markdown("---")
    res = st.session_state['search_results']
    cols = st.columns(5)
    for i, item in enumerate(res):
        with cols[i % 5]:
            # [íŒíŠ¸ ì ìš©] 6464ë²ˆ ë¼ì¸ì˜ ì§ì ‘ URL ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì—‘ë°• ë°©ì§€ ë° ì†ë„ í–¥ìƒ
            st.image(item['url'], use_container_width=True)
            st.markdown(f"**{item['formal']}**")
            st.caption(f"{item['name']} ({item['score']:.1%})")
            st.info(f"ì¬ê³ : {item['stock']:,}m")
