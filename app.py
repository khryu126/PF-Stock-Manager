import streamlit as st
import pandas as pd
import numpy as np
from rapidfuzz import process, utils
import re
import google.generativeai as genai
from datetime import datetime, timedelta

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ì„±ì§€ë¼ë¯¸í… íŠ¹íŒ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì‹œìŠ¤í…œ", layout="wide")

# --- 2. AI ê²€ìƒ‰ ì—”ì§„ ì„¤ì • (Gemini) ---
# ValueError ë°©ì§€ë¥¼ ìœ„í•´ tools ì„¤ì • í˜•ì‹ì„ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    # ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ì¤€ êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬ ì„¤ì • ë°©ì‹
    try:
        # 'google_search_retrieval' ë„êµ¬ ì‚¬ìš©
        model = genai.GenerativeModel(
            'gemini-1.5-pro',
            tools=[{"google_search_retrieval": {}}]
        )
    except Exception as e:
        # ìœ„ ë°©ì‹ì´ ì‹¤íŒ¨í•  ê²½ìš° ê¸°ë³¸ ëª¨ë¸ë¡œ ë¡œë“œ
        model = genai.GenerativeModel('gemini-1.5-pro')
        st.sidebar.error(f"AI ë„êµ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    st.sidebar.warning("âš ï¸ Secretsì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

def get_ai_search_result(site_name):
    prompt = f"ê±´ì„¤ í˜„ì¥ëª… ë˜ëŠ” ì§€ë²ˆ '{site_name}'ì— ëŒ€í•´ ì¸í„°ë„·ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ì‹¤ì œ ì•„íŒŒíŠ¸ ë‹¨ì§€ëª…, ë¸Œëœë“œëª…, ì‹œê³µì‚¬ ì •ë³´ë¥¼ ì§§ê³  ëª…í™•í•˜ê²Œ ìš”ì•½í•´ì¤˜."
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"AI ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# --- 3. ë°ì´í„° ë¡œë“œ ë° ì •ì œ í•¨ìˆ˜ ---
def safe_read_csv(file, skiprows=0):
    if file is not None:
        for enc in ['cp949', 'utf-8-sig', 'utf-8']:
            try:
                file.seek(0)
                df = pd.read_csv(file, encoding=enc, skiprows=skiprows)
                df.columns = df.columns.str.strip()
                return df
            except:
                continue
    return None

def to_numeric(series):
    return pd.to_numeric(series.astype(str).str.replace(',', '').str.strip(), errors='coerce').fillna(0)

def clean_site_name(name):
    if not name or pd.isna(name): return ""
    # ë¶ˆí•„ìš”í•œ ë…¸ì´ì¦ˆ ì œê±°
    name = re.sub(r'\(ì£¼\)|ì£¼ì‹íšŒì‚¬|ì‹ ì¶•ê³µì‚¬|í˜„ì¥|ì¼ëŒ€|M/H|MH|S/H|SH|ìƒ˜í”Œ', '', str(name))
    name = " ".join(name.split())
    return name

# --- 4. ì‚¬ì´ë“œë°”: ë°ì´í„° ì—…ë¡œë“œ ---
st.sidebar.header("ğŸ“ ë°ì´í„° ì†ŒìŠ¤ ì—…ë¡œë“œ")
f_expected = st.sidebar.file_uploader("1. ìˆ˜ì£¼ì˜ˆì •ë“±ë¡.csv", type="csv")
f_stock = st.sidebar.file_uploader("2. í˜„ì¬ê³ .csv", type="csv")
f_history = st.sidebar.file_uploader("3. ì¶œê³ ë‚´ì—­.csv", type="csv")
f_item = st.sidebar.file_uploader("4. í’ˆëª©ì •ë³´.csv", type="csv")
f_retail = st.sidebar.file_uploader("5. ì‹œíŒìŠ¤í™ê´€ë¦¬.csv", type="csv")
f_po = st.sidebar.file_uploader("6. PO.csv", type="csv")

df_exp = safe_read_csv(f_expected, skiprows=1)
df_stk = safe_read_csv(f_stock)
df_his = safe_read_csv(f_history)
df_itm = safe_read_csv(f_item)
df_rtl = safe_read_csv(f_retail)
df_po = safe_read_csv(f_po)

st.title("ğŸ›¡ï¸ ì„±ì§€ë¼ë¯¸í… íŠ¹íŒ ë¦¬ìŠ¤í¬ ê´€ë¦¬")

if df_exp is not None and df_stk is not None:
    # ë°ì´í„° ì „ì²˜ë¦¬
    df_exp['ìˆ˜ì£¼ì”ëŸ‰_n'] = to_numeric(df_exp['ìˆ˜ì£¼ì”ëŸ‰'])
    df_stk['ì¬ê³ ìˆ˜ëŸ‰_n'] = to_numeric(df_stk['ì¬ê³ ìˆ˜ëŸ‰'])
    
    # í‰ëŸ‰ ë§¤í•‘
    weight_map = {}
    if df_itm is not None:
        w_col = 'B/Pë¬´ê²Œ' if 'B/Pë¬´ê²Œ' in df_itm.columns else 'B/P weight' if 'B/P weight' in df_itm.columns else None
        if w_col:
            weight_map = df_itm.set_index('ìƒí’ˆì½”ë“œ')[w_col].to_dict()

    tab1, tab2 = st.tabs(["ğŸ“ í˜„ì¥ ëˆ„ë½ ë°©ì§€ ì ê²€", "ğŸ“… ì˜¤ë” ì‹œì  ë° ì¬ê³  ì˜ˆì¸¡"])

    with tab1:
        st.subheader("ğŸ¢ íŠ¹íŒ í˜„ì¥(M/H, S/H) ì¶œê³  ê¸°ë°˜ ë“±ë¡ ì—¬ë¶€ í™•ì¸")
        if df_his is not None:
            target_keywords = ['M/H', 'MH', 'S/H', 'SH']
            mh_pattern = '|'.join(target_keywords)
            mh_deliveries = df_his[
                df_his['í˜„ì¥ëª…'].str.contains(mh_pattern, na=False, case=False) |
                df_his['ë¹„ê³ '].str.contains(mh_pattern, na=False, case=False)
            ].copy()

            if not mh_deliveries.empty:
                unique_sites = mh_deliveries['í˜„ì¥ëª…'].unique()
                expected_sites = df_exp['í˜„ì¥ëª…'].unique()
                clean_exp_list = [clean_site_name(s) for s in expected_sites]
                exp_map = {clean_site_name(s): s for s in expected_sites}

                for site in unique_sites:
                    c_site = clean_site_name(site)
                    match = process.extractOne(c_site, clean_exp_list, processor=utils.default_process)
                    score = match[1] if match else 0
                    match_original = exp_map.get(match[0]) if match else "ì—†ìŒ"
                    status = "âœ… ë“±ë¡ë¨" if score > 85 else "âš ï¸ ëˆ„ë½ ì˜ì‹¬" if score > 50 else "ğŸ”´ ë¯¸ë“±ë¡"
                    
                    col_a, col_b, col_c, col_d = st.columns([3, 3, 1, 2])
                    with col_a: st.write(f"**ì¶œê³ ëª…:** {site}")
                    with col_b: st.write(f"**ë§¤ì¹­:** {match_original} ({score:.1f}%)")
                    with col_c: st.write(status)
                    with col_d:
                        if status != "âœ… ë“±ë¡ë¨" and "GOOGLE_API_KEY" in st.secrets:
                            if st.button(f"ğŸ” AI ê²€ìƒ‰", key=f"btn_{site}"):
                                with st.spinner('AI ê²€ìƒ‰ ì¤‘...'):
                                    st.info(get_ai_search_result(site))
            else:
                st.write("M/H ì¶œê³  ê±´ì´ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        st.subheader("ğŸ“Š ì¬ê³  ìˆ˜ì§€ ì‹œë®¬ë ˆì´ì…˜")
        target_item = st.selectbox("í’ˆë²ˆ ì„ íƒ", df_exp['ìƒí’ˆì½”ë“œ'].unique())
        
        curr_inv = df_stk[df_stk['í’ˆë²ˆ'] == target_item]['ì¬ê³ ìˆ˜ëŸ‰_n'].sum()
        po_m = 0
        if df_po is not None:
            po_data = df_po[df_po['í’ˆë²ˆ'] == target_item]
            bw = weight_map.get(target_item, 70)
            po_m = (to_numeric(po_data['PO ìˆ˜ëŸ‰']).sum() * 1000) / (bw * 1.26)
        
        retail_monthly = 0
        if df_rtl is not None:
            rtl_match = df_rtl[df_rtl['í’ˆë²ˆ'] == target_item]
            if not rtl_match.empty:
                retail_monthly = to_numeric(rtl_match['4ê°œì›”íŒë§¤ëŸ‰']).values[0] / 4

        # ë¯¸ë˜ ì¬ê³  ì‹œë®¬ë ˆì´ì…˜ ê·¸ë˜í”„
        months = [(datetime.now() + timedelta(days=30*i)).strftime("%Y-%m") for i in range(1, 7)]
        sim_balance = curr_inv + po_m
        graph_data = []
        for m in months:
            sim_balance -= retail_monthly
            graph_data.append({"ì›”": m, "ì˜ˆìƒì¬ê³ ": max(0, sim_balance)})
        
        st.line_chart(pd.DataFrame(graph_data).set_index("ì›”"))
        st.write(f"ìµœì¢… ì˜ˆìƒ ì¬ê³ (6ê°œì›” ë’¤): {sim_balance:,.0f} m")

else:
    st.warning("íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
