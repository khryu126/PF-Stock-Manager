import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta

# --- [1. ì„¤ì • ë° ë¦¬ë“œíƒ€ì„ ë§ˆìŠ¤í„°] ---
st.set_page_config(page_title="PÂ·Forecast Stock Manager", layout="wide")

LT_CONFIG = {
    'SE': {'total': 6, 'ship_days': 90},
    'SR': {'total': 8, 'ship_days': 90},
    'SRL': {'total': 8, 'ship_days': 90},
    'SP': {'total': 8, 'ship_days': 90},
    'SH': {'total': 1, 'ship_days': 30},
    'KD': {'total': 2, 'ship_days': 30},
    'QZ': {'total': 2, 'ship_days': 30}
}

# --- [2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---
def clean_numeric(series):
    if series.dtype == 'object':
        series = series.astype(str).str.replace(r'[^\d.-]', '', regex=True)
        series = series.replace(['', 'nan', 'None'], np.nan)
    return pd.to_numeric(series, errors='coerce').fillna(0)

def parse_date_smart(series):
    s = series.astype(str).str.replace('.0', '', regex=False).str.strip()
    return pd.to_datetime(s, format='%Y%m%d', errors='coerce')

def find_col_precise(df, keywords, exclude_keywords=None, default_idx=None):
    for k in keywords:
        for col in df.columns:
            col_upper = str(col).replace(" ", "").upper()
            if k in col_upper:
                if exclude_keywords:
                    if any(ex.upper() in col_upper for ex in exclude_keywords): continue
                return col
    if default_idx is not None and len(df.columns) > default_idx:
        return df.columns[default_idx]
    return None

def smart_load_csv(file):
    for enc in ['cp949', 'utf-8-sig', 'utf-8']:
        try:
            file.seek(0)
            df = pd.read_csv(file, encoding=enc)
            if df.columns.str.contains('Unnamed').sum() > len(df.columns) * 0.3:
                for i in range(1, 20):
                    file.seek(0)
                    df = pd.read_csv(file, skiprows=i, encoding=enc)
                    if not df.columns.str.contains('Unnamed').all(): break
            df.columns = [str(c).strip() for c in df.columns]
            return df
        except: continue
    return None

# --- [3. ìƒì„¸ ìˆ˜ì£¼ íŒì—… (ì”ëŸ‰ 0 ì œì™¸ ë° ì‹œê¸‰ìˆœ ì •ë ¬)] ---
@st.dialog("ìƒì„¸ ìˆ˜ì£¼ ë‚´ì—­", width="large")
def show_detail_popup(group_ids, df_bl, cutoff_date):
    st.markdown(f"#### ğŸ” ë¶„ì„ ëŒ€ìƒ í’ˆë²ˆ ê·¸ë£¹: `{', '.join(group_ids)}`")
    
    code_col = find_col_precise(df_bl, ['ìƒí’ˆì½”ë“œ', 'í’ˆë²ˆ'], default_idx=5)
    qty_col = find_col_precise(df_bl, ['ìˆ˜ì£¼ì”ëŸ‰', 'ì”ëŸ‰'], default_idx=30)
    
    group_upper = [g.upper() for g in group_ids]
    detail = df_bl[df_bl[code_col].astype(str).str.upper().str.strip().isin(group_upper)].copy()
    detail['clean_qty'] = clean_numeric(detail[qty_col])
    
    # ë‚©ê¸°ì¼ì íŒŒì‹± (ì¸ë±ìŠ¤ 24)
    detail['dt_clean_popup'] = pd.to_datetime(detail.iloc[:, 24].astype(str).str.replace('.0',''), format='%Y%m%d', errors='coerce')
    
    # [ìš”ì²­ì‚¬í•­] ìˆ˜ì£¼ì”ëŸ‰ 0 ì œì™¸ ë° ë‚©ê¸° ê°€ì¥ ë¹ ë¥¸ ìˆœ(ì˜¤ë¦„ì°¨ìˆœ) ì •ë ¬
    detail = detail[(detail['clean_qty'] > 0) & (detail['dt_clean_popup'] >= cutoff_date)]
    
    if detail.empty:
        st.info("ì¡°ê±´ì— ë§ëŠ” ë¯¸ì¶œê³  ìˆ˜ì£¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    st.dataframe(
        detail.sort_values('dt_clean_popup', ascending=True), 
        use_container_width=True, hide_index=True
    )

# --- [4. ë©”ì¸ UI ë° ì‚¬ì´ë“œë°” (ì •ì˜ í•„ìˆ˜)] ---
st.title("ğŸš€ PÂ·Forecast Stock Manager v6.8")

RECOGNITION = {
    "backlog": {"name": "ìˆ˜ì£¼ì˜ˆì •(Demand)", "keys": ["ìˆ˜ì£¼ì”ëŸ‰", "ì´ì˜ˆìƒìˆ˜ëŸ‰"], "found": False},
    "po": {"name": "êµ¬ë§¤ë°œì£¼(PO)", "keys": ["POì”ëŸ‰", "ë¯¸ì„ ì "], "found": False},
    "stock": {"name": "í˜„ì¬ê³ (Stock)", "keys": ["ì¬ê³ ìˆ˜ëŸ‰", "í˜„ì¬ê³ ì•¡"], "found": False},
    "item": {"name": "í’ˆëª©ì •ë³´(Master)", "keys": ["ìµœì¢…ìƒì‚°ì§€ëª…", "ì´ì „ìƒí’ˆì½”ë“œ"], "found": False},
    "retail": {"name": "ì‹œíŒìŠ¤í™(Retail)", "keys": ["ì¶œì‹œì˜ˆì •", "4ê°œì›”íŒë§¤ëŸ‰"], "found": False}
}

with st.sidebar:
    st.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
    default_start = (datetime.now().replace(day=1) + relativedelta(months=1))
    start_date_val = st.date_input("ê²€í†  ì‹œì (ì¡°íšŒ ì‹œì‘ì¼)", default_start)
    freq_opt = st.selectbox("ì§‘ê³„ ë‹¨ìœ„", ["ì£¼ë³„", "ì›”ë³„", "ë¶„ê¸°ë³„", "ë…„ë„ë³„"], index=1)
    exclude_months = st.slider("ê³¼ê±° ìˆ˜ì£¼ ì œì™¸ (Nê°œì›”)", 1, 36, 12)
    cutoff_date = pd.Timestamp(start_date_val) - relativedelta(months=exclude_months)
    st.markdown("---")
    search_query = st.text_input("ğŸ” í’ˆëª…/í’ˆë²ˆ í‚¤ì›Œë“œ ê²€ìƒ‰", "")
    st.markdown("---")
    uploaded_files = st.file_uploader("5ì¢… CSV íŒŒì¼ ì—…ë¡œë“œ", accept_multiple_files=True)
    
    # [v6.8 ì¶”ê°€] ë¶„ì„ ì‹¤í–‰ ë²„íŠ¼ - ëˆ„ë¥´ê¸° ì „ê¹Œì§€ëŠ” (1/227) ë¡œë”©ì´ ê±¸ë¦¬ì§€ ì•ŠìŒ
    run_button = st.button("ğŸ“Š ìˆ˜ê¸‰ ë¶„ì„ ì‹œì‘/ê°±ì‹ ", type="primary", use_container_width=True)

# íŒŒì¼ ë¡œë“œ ë° ë¶„ë¥˜
data_files = {}
if uploaded_files:
    for f in uploaded_files:
        df = smart_load_csv(f)
        if df is not None:
            cols_text = "|".join(df.columns).upper()
            for k, v in RECOGNITION.items():
                if any(key in cols_text for key in v["keys"]):
                    data_files[k] = df; RECOGNITION[k]["found"] = True; break

# --- [5. ì‹œë®¬ë ˆì´ì…˜ ì—”ì§„] ---
def run_simulation():
    # ì§„í–‰ë¥  í‘œì‹œì¤„ ìƒì„±
    progress_bar = st.progress(0, text="ë°ì´í„° ë¶„ì„ ì¤‘...")
    
    df_item, df_bl, df_po, df_st, df_retail = data_files['item'], data_files['backlog'], data_files['po'], data_files['stock'], data_files['retail']
    today_dt = pd.Timestamp(datetime.now().date())
    base_dt = pd.Timestamp(start_date_val)

    # ë§ˆìŠ¤í„° ì •ë³´ êµ¬ì¶• (ìµœì‹ ìˆœ)
    it_code = find_col_precise(df_item, ['ìƒí’ˆì½”ë“œ', 'í’ˆë²ˆ'], exclude_keywords=['ëŒ€í‘œ'], default_idx=6)
    it_site = find_col_precise(df_item, ['ìµœì¢…ìƒì‚°ì§€ëª…', 'ìƒì‚°ì§€'], default_idx=12)
    it_prev = find_col_precise(df_item, ['ì´ì „ìƒí’ˆì½”ë“œ'], default_idx=13)
    it_date = find_col_precise(df_item, ['ìƒì„±ì¼ì'], default_idx=3)
    it_name = find_col_precise(df_item, ['ìƒí’ˆëª…', 'í’ˆëª…'], default_idx=1)

    master_proc = df_item.copy()
    master_proc['clean_date'] = parse_date_smart(master_proc[it_date])
    master_proc['key_u'] = master_proc[it_code].astype(str).str.upper().str.strip()
    master_proc = master_proc.sort_values(by=['key_u', 'clean_date'], ascending=[True, False])
    master_unique = master_proc.drop_duplicates(subset='key_u', keep='first')

    site_map = master_unique.set_index('key_u')[it_site].to_dict()
    prev_map = master_unique.set_index('key_u')[it_prev].to_dict()
    next_map = master_unique.set_index(master_unique[it_prev].astype(str).str.upper().str.strip())[it_code].to_dict()

    # ì†ŒìŠ¤ ë°ì´í„° ì •ì œ
    bl_code_col = find_col_precise(df_bl, ['ìƒí’ˆì½”ë“œ', 'í’ˆë²ˆ'], default_idx=5)
    df_bl['clean_qty'] = clean_numeric(df_bl[find_col_precise(df_bl, ['ìˆ˜ì£¼ì”ëŸ‰', 'ì´ì˜ˆìƒìˆ˜ëŸ‰'], default_idx=30)])
    df_bl['dt_clean'] = parse_date_smart(df_bl[find_col_precise(df_bl, ['ë‚©í’ˆì˜ˆì •ì¼'], default_idx=24)])
    df_bl_filtered = df_bl[df_bl['dt_clean'] >= cutoff_date].copy()

    po_code_col = find_col_precise(df_po, ['í’ˆë²ˆ', 'ìƒí’ˆì½”ë“œ'], default_idx=12)
    df_po['m_qty'] = clean_numeric(df_po[find_col_precise(df_po, ['POì”ëŸ‰', 'ë¯¸ì„ ì '], default_idx=19)]) * 11.3378 

    # ë¦¬ë“œíƒ€ì„ ë° ì…ê³ ì¼ ê³„ì‚°
    def calc_arrival(row):
        pid_u = str(row[po_code_col]).upper().strip()
        site_v = str(row.get(find_col_precise(df_po, ['ìƒì‚°ì§€ëª…', 'ê±°ë˜ì²˜'], default_idx=10), site_map.get(pid_u, 'ETC'))).upper()
        site_k = 'SR' if 'SR' in site_v else site_v[:2]
        lt = LT_CONFIG.get(site_k, LT_CONFIG.get(site_v[:2], {'total': 1, 'ship_days': 30}))
        p_dt = parse_date_smart(pd.Series([row.get(find_col_precise(df_po, ['ìƒì‚°ì˜ˆì •ì¼'], default_idx=28), np.nan)]))[0]
        if pd.notnull(p_dt): arrival = p_dt + pd.DateOffset(days=int(lt['ship_days']))
        else:
            b_dt = parse_date_smart(pd.Series([row.get(find_col_precise(df_po, ['POì¼ì', 'ë°œì£¼ì¼ì'], default_idx=3), today_dt)]))[0]
            if pd.isna(b_dt): b_dt = today_dt
            arrival = b_dt + pd.DateOffset(months=int(lt['total']))
        if pd.isnull(arrival) or arrival < base_dt:
            arrival = today_dt + pd.DateOffset(days=int(lt['ship_days']))
            if arrival < base_dt: arrival = base_dt
        return arrival

    df_po['dt_arrival'] = df_po.apply(calc_arrival, axis=1)
    df_st['clean_qty'] = clean_numeric(df_st[find_col_precise(df_st, ['ì¬ê³ ìˆ˜ëŸ‰', 'í˜„ì¬ê³ '], default_idx=7)])

    # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
    freq_map = {"ì£¼ë³„": "W", "ì›”ë³„": "MS", "ë¶„ê¸°ë³„": "QS", "ë…„ë„ë³„": "YS"}
    date_range = pd.date_range(start=base_dt, periods=13, freq=freq_map[freq_opt])
    time_labels = [d.strftime('%Y-%m-%d' if freq_opt=="ì£¼ë³„" else '%Y-%m') for d in date_range[:12]]

    target_ids = df_bl_filtered[df_bl_filtered['clean_qty'] > 0][bl_code_col].unique()
    matrix_rows, alert_list = [], []
    
    for i, pid in enumerate(target_ids):
        pid_s = str(pid).strip(); pid_u = pid_s.upper()
        item_match = master_unique[master_unique['key_u'] == pid_u]
        p_name = str(item_match[it_name].iloc[0]) if not item_match.empty else "-"
        
        # [v6.8] ë¡œë”© ê²Œì´ì§€ ì—…ë°ì´íŠ¸
        progress_bar.progress((i + 1) / len(target_ids), text=f"ğŸ” ë¶„ì„ ì¤‘ ({i+1}/{len(target_ids)}): {p_name[:10]}...")

        def clean_p(v):
            s = str(v).strip().upper()
            return s if s not in ["NAN", "NONE", "0", "-", ""] else ""
        p_id = clean_p(prev_map.get(pid_u, "")); n_id = clean_p(next_map.get(pid_u, ""))
        group = list(set([pid_u, p_id, n_id])); group = [g for g in group if g]

        site_name = str(site_map.get(pid_u, "ETC"))
        site_key = 'SR' if 'SR' in site_name.upper() else site_name[:2].upper()
        lt_total = LT_CONFIG.get(site_key, {'total': 0})['total']

        main_stk = df_st[df_st[find_col_precise(df_st, ['í’ˆë²ˆ', 'ìƒí’ˆì½”ë“œ'], default_idx=7)].astype(str).str.upper().str.strip().isin(group)]['clean_qty'].sum()
        overdue_dem = df_bl_filtered[(df_bl_filtered[bl_code_col].astype(str).str.upper().str.strip().isin(group)) & (df_bl_filtered['dt_clean'] < base_dt)]['clean_qty'].sum()
        running_inv = main_stk - overdue_dem
        
        d_row = {"No": i+1, "í’ˆëª…": p_name, "ìˆ˜ì£¼í’ˆë²ˆ": pid_s, "ë³¸ì‚¬ì¬ê³ ": main_stk, "POì”ëŸ‰(m)": df_po[df_po[po_code_col].astype(str).str.upper().str.strip().isin(group)]['m_qty'].sum(), "ìƒì‚°ì§€": f"{site_key}({lt_total}M)", "êµ¬ë¶„": "ì†Œìš”ëŸ‰", "ì—°ê³„ì •ë³´": f"ì´ì „:{p_id}" if p_id else "", "ë‚©ê¸°ê²½ê³¼": overdue_dem, "group": group}
        p_row = {"No": i+1, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ì¬ê³ ": np.nan, "POì”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "êµ¬ë¶„": "ì…ê³ ëŸ‰(PO)", "ì—°ê³„ì •ë³´": "", "ë‚©ê¸°ê²½ê³¼": 0, "group": group}
        s_row = {"No": i+1, "í’ˆëª…": "", "ìˆ˜ì£¼í’ˆë²ˆ": "", "ë³¸ì‚¬ì¬ê³ ": np.nan, "POì”ëŸ‰(m)": np.nan, "ìƒì‚°ì§€": "", "êµ¬ë¶„": "ì˜ˆìƒì¬ê³ ", "ì—°ê³„ì •ë³´": f"ë³€ê²½:{n_id}" if n_id else "", "ë‚©ê¸°ê²½ê³¼": running_inv, "group": group}

        for j in range(12):
            start, end = date_range[j], date_range[j+1]
            m_dem = df_bl_filtered[(df_bl_filtered[bl_code_col].astype(str).str.upper().str.strip().isin(group)) & (df_bl_filtered['dt_clean'] >= start) & (df_bl_filtered['dt_clean'] < end)]['clean_qty'].sum()
            m_sup = df_po[(df_po[po_code_col].astype(str).str.upper().str.strip().isin(group)) & (df_po['dt_arrival'] >= start) & (df_po['dt_arrival'] < end)]['m_qty'].sum()
            running_inv = (running_inv + m_sup) - m_dem
            lbl = time_labels[j]
            d_row[lbl], p_row[lbl], s_row[lbl] = m_dem, m_sup, running_inv
            if running_inv < 0 and start < base_dt + pd.DateOffset(months=lt_total):
                alert_list.append({"í’ˆëª…": p_name, "í’ˆë²ˆ": pid_s, "ìƒì‚°ì§€": site_key, "LT": lt_total, "ë¶€ì¡±ì‹œì ": lbl, "ë¶€ì¡±ìˆ˜ëŸ‰": abs(running_inv), "group": group})
        matrix_rows.extend([d_row, p_row, s_row])

    progress_bar.empty()
    return pd.DataFrame(matrix_rows), pd.DataFrame(alert_list), time_labels

# --- [6. ë©”ì¸ ë¡œì§ ì œì–´] ---
if len(data_files) >= 5:
    # ë¶„ì„ ë°ì´í„°ê°€ ì„¸ì…˜ì— ì—†ê±°ë‚˜ 'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œë§Œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    if 'sim_data' not in st.session_state or run_button:
        res, alerts, labels = run_simulation()
        st.session_state.sim_data = {'res': res, 'alerts': alerts, 'labels': labels}

    res_df = st.session_state.sim_data['res']
    alert_df = st.session_state.sim_data['alerts']
    time_labels = st.session_state.sim_data['labels']

    # 1. ê¸´ê¸‰ ë°œì£¼ ëŒ€ì‹œë³´ë“œ (ìµœìƒë‹¨ ë…¸ì¶œ)
    st.subheader("ğŸš¨ ìˆ˜ê¸‰ ì•ˆì •ì„± ê²€í†  (ê¸´ê¸‰ í’ˆëª©)")
    if not alert_df.empty:
        alert_clean = alert_df.drop_duplicates(subset=['í’ˆë²ˆ'], keep='first').copy()
        
        def get_dday(row):
            deadline = pd.to_datetime(row['ë¶€ì¡±ì‹œì ']) - pd.DateOffset(months=int(row['LT']))
            days = (deadline - pd.Timestamp(datetime.now().date())).days
            return f"D-{days}ì¼" if days >= 0 else f"ì§€ë‚¨({abs(days)}ì¼ ì „)"
        
        alert_clean['ë°œì£¼ê¸°í•œ'] = alert_clean.apply(get_dday, axis=1)
        
        # ê¸´ê¸‰ ë¦¬ìŠ¤íŠ¸ í´ë¦­ ì‹œ ìƒì„¸ë³´ê¸° ì—°ë™
        sel_alert = st.dataframe(
            alert_clean[['í’ˆëª…', 'í’ˆë²ˆ', 'ìƒì‚°ì§€', 'ë¶€ì¡±ì‹œì ', 'ë¶€ì¡±ìˆ˜ëŸ‰', 'ë°œì£¼ê¸°í•œ']], 
            use_container_width=True, hide_index=True, on_select="rerun", selection_mode="single-row"
        )
        if sel_alert.selection.rows:
            target = alert_clean.iloc[sel_alert.selection.rows[0]]
            # [v6.8 í•µì‹¬] ëˆ„ë¥´ë©´ ë°”ë¡œ í•´ë‹¹ í’ˆë²ˆ íŒì—… ë…¸ì¶œ
            if st.button(f"ğŸ” {target['í’ˆë²ˆ']} ìƒì„¸ë³´ê¸° (ê¸´ê¸‰ ë¦¬ìŠ¤íŠ¸ìš©)", type="primary"):
                show_detail_popup(target['group'], data_files['backlog'], cutoff_date)
    else:
        st.success("ì•ˆì „: ë¦¬ë“œíƒ€ì„ ë‚´ ë¶€ì¡± ì˜ˆì • í’ˆëª©ì´ ì—†ìŠµë‹ˆë‹¤.")

    # 2. ë©”ì¸ ì‹œë®¬ë ˆì´ì…˜ ë§¤íŠ¸ë¦­ìŠ¤
    st.subheader(f"ğŸ“Š í†µí•© ìˆ˜ê¸‰ ë¶„ì„ ë§¤íŠ¸ë¦­ìŠ¤")
    if search_query:
        res_df = res_df[res_df['í’ˆëª…'].str.contains(search_query, case=False) | res_df['ìˆ˜ì£¼í’ˆë²ˆ'].str.contains(search_query, case=False)]

    num_cols = ["ë³¸ì‚¬ì¬ê³ ", "POì”ëŸ‰(m)", "ë‚©ê¸°ê²½ê³¼"] + time_labels
    def style_fn(row):
        g_idx = (row.name // 3); bg = '#f9f9f9' if g_idx % 2 == 0 else '#ffffff'
        styles = [f'background-color: {bg}'] * len(row)
        for i, col in enumerate(row.index):
            if col == "êµ¬ë¶„": styles[i] = 'background-color: #e1f5fe; font-weight: bold'
            elif row['êµ¬ë¶„'] == "ì˜ˆìƒì¬ê³ " and col in num_cols and row[col] < 0:
                styles[i] = 'background-color: #ff4b4b; color: white'
        return styles

    st_df = st.dataframe(
        res_df.style.apply(style_fn, axis=1).format({c: "{:,.0f}" for c in num_cols}, na_rep=""),
        use_container_width=True, hide_index=True, on_select="rerun", selection_mode="single-row",
        column_order=["No", "í’ˆëª…", "ìˆ˜ì£¼í’ˆë²ˆ", "ë³¸ì‚¬ì¬ê³ ", "POì”ëŸ‰(m)", "ìƒì‚°ì§€", "ì—°ê³„ì •ë³´", "êµ¬ë¶„", "ë‚©ê¸°ê²½ê³¼"] + time_labels
    )
    
    if st_df.selection.rows:
        target = res_df.iloc[st_df.selection.rows[0] - (st_df.selection.rows[0] % 3)]
        if st.button(f"ğŸ” {str(target['ìˆ˜ì£¼í’ˆë²ˆ']).strip()} ìƒì„¸ ë‚´ì—­ ë³´ê¸°"):
            show_detail_popup(target['group'], data_files['backlog'], cutoff_date)
else:
    st.info("ì‚¬ì´ë“œë°”ì— 5ì¢… íŒŒì¼ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
